<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Drowning in forum posts - PADDLE</title><meta name="description" content="This text by Thomas Hillman details a relatively simple way of scrapping and organizing data from online forums that do not provide API access without the need to code. Obviously, writing simple scripts using libraries like Beautiful Soup for Python is a more efficient way to work, but it requires a good amount of effort to learn the basics of programming. This effort is worth it in the end, but in the mean time it is good to have work arounds."><meta name="robots" content="index, follow"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://paddle-cluster.github.io/drowning-in-forum-posts.html"><link rel="alternate" type="application/atom+xml" href="https://paddle-cluster.github.io/feed.xml"><link rel="alternate" type="application/json" href="https://paddle-cluster.github.io/feed.json"><meta property="og:title" content="Drowning in forum posts"><meta property="og:site_name" content="PADDLE"><meta property="og:description" content="This text by Thomas Hillman details a relatively simple way of scrapping and organizing data from online forums that do not provide API access without the need to code. Obviously, writing simple scripts using libraries like Beautiful Soup for Python is a more efficient way to work, but it requires a good amount of effort to learn the basics of programming. This effort is worth it in the end, but in the mean time it is good to have work arounds."><meta property="og:url" content="https://paddle-cluster.github.io/drowning-in-forum-posts.html"><meta property="og:type" content="article"><link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700|Roboto:400,700&amp;subset=latin-ext&amp;display=swap" rel="stylesheet"><style>h1,h2,h3,h4,h5,h6,.btn,[type=button],[type=submit],button,.navbar .navbar__menu li,.navbar_mobile_sidebar .navbar__menu li,.feed__author,.post__tag,.post__share>a span,.post__nav-link>span,.footer{font-family:'Roboto',sans-serif}body,blockquote,.search__input,.author__name,.author__info>p,.post__nav-link{font-family:'Open Sans',sans-serif}</style><link rel="stylesheet" href="https://paddle-cluster.github.io/assets/css/style.css?v=c27067b18488b46c6b2a3c5bb4ef3af4"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://paddle-cluster.github.io/drowning-in-forum-posts.html"},"headline":"Drowning in forum posts","datePublished":"2020-03-01T11:48","dateModified":"2020-03-01T11:57","description":"<p data-selectable-paragraph=\"\">This text by <a href=\"https://paddle-cluster.github.io/thomas-hillman.html\">Thomas Hillman</a> details a relatively simple way of scrapping and organizing data from online forums that do not provide API access without the need to code. Obviously, writing simple scripts using libraries like Beautiful Soup for Python is a more efficient way to work, but it requires a good amount of effort to learn the basics of programming. This effort is worth it in the end, but in the mean time it is good to have work arounds.</p>\n","author":{"@type":"Person","name":"Thomas Hillman"},"publisher":{"@type":"Organization","name":"Thomas Hillman"}}</script><script src="https://paddle-cluster.github.io/assets/js/ls.parent-fit.min.js?v=1c78585e2a70398fe95085061942fd37"></script><script async src="https://paddle-cluster.github.io/assets/js/lazysizes.min.js?v=149ff45fc6c2f13e892e438a58abb77f"></script></head><body><div class="site-container"><header class="top" id="js-header"><a class="logo" href="https://paddle-cluster.github.io/">PADDLE</a><nav class="navbar js-navbar"><button class="navbar__toggle js-toggle" aria-label="Menu" aria-haspopup="true" aria-expanded="false"><span class="navbar__toggle-box"><span class="navbar__toggle-inner">Menu</span></span></button><ul class="navbar__menu"><li class="has-submenu"><a href="https://paddle-cluster.github.io/platforms-automation-digital-data-learning-and-expertise.html" target="_self" aria-haspopup="true">English</a><ul class="navbar__submenu level-2" aria-hidden="true"><li><a href="https://paddle-cluster.github.io/project/" target="_self">Projects</a></li><li><a href="https://paddle-cluster.github.io/member/" target="_self">Members</a></li><li><a href="https://paddle-cluster.github.io/reading/" target="_self">Reading lists</a></li><li><a href="https://paddle-cluster.github.io/method/" target="_self">Methods</a></li><li class="has-submenu"><a href="https://medium.com/tag/paddle-cluster" target="_self" aria-haspopup="true">Blog</a><ul class="navbar__submenu level-3" aria-hidden="true"><li><a href="https://medium.com/tag/balanced-gu" target="_self">BalancED</a></li></ul></li></ul></li><li class="has-submenu"><a href="https://paddle-cluster.github.io/platforms-automation-digital-data-learning-and-expertise.html" target="_self" aria-haspopup="true">Svenska</a><ul class="navbar__submenu level-2" aria-hidden="true"><li><a href="https://paddle-cluster.github.io/projekt/" target="_self">Projekt</a></li><li><a href="https://paddle-cluster.github.io/medlem/" target="_self">Medlemmar</a></li><li><a href="https://paddle-cluster.github.io/laeslista/" target="_self">Läslistor</a></li><li><a href="https://paddle-cluster.github.io/method/" target="_self">Metoder</a></li><li class="has-submenu"><a href="https://medium.com/tag/paddle-cluster" target="_self" aria-haspopup="true">Blogg</a><ul class="navbar__submenu level-3" aria-hidden="true"><li><a href="https://medium.com/tag/balanced-gu" target="_self">BalancED</a></li></ul></li></ul></li></ul></nav></header><main><article class="post"><div class="hero"><header class="hero__content"><div class="wrapper"><h1>Drowning in forum posts</h1></div></header></div><div class="wrapper post__entry"><p data-selectable-paragraph="">This text by <a href="https://paddle-cluster.github.io/thomas-hillman.html">Thomas Hillman</a> details a relatively simple way of scrapping and organizing data from online forums that do not provide API access without the need to code. Obviously, writing simple scripts using libraries like Beautiful Soup for Python is a more efficient way to work, but it requires a good amount of effort to learn the basics of programming. This effort is worth it in the end, but in the mean time it is good to have work arounds.</p><p id="da89" data-selectable-paragraph="">My training as a social scientist has focused on ethnographic methods and the use of detailed video ethnography has been the cornerstone of my research practice. But, like many social scientists in the last few years, my attention has turned more and more to online interactions between people and this has posed significant challenges. As many have lamented, the sheer volume of data that must be managed is in many ways incompatible with the detailed, situated approaches I am trained in. Finding ways to sort through enormous flows of interactions and make rigorous choices about which interactions to focus my detailed analysis on has proven to be both fascinating and frustrating. A case in point is my current work to understand informal learning in communities of amateur ‘citizen scientists’ who contribute to large science projects through their efforts online. One of the communities I am studying has had an active discussion forum for the past eight years and finding a way to manage 650,000 posts, many of which form detailed scientific discussions that take place over several months, has forced me to find new ways of working.</p><h2 id="7d34" class="jz ka cv v ba fh ib kb id kc kd ke kf kg kh ki kj">Collecting the avalanche</h2><p id="422d" class="jm jn cv v ab b jo kk jq kl js km ju kn jw ko jy gk" data-selectable-paragraph="">650,000 posts means that just ‘browsing’ the forum site in an attempt to find something significant to focus on is not practical. Beyond which, while I have taken a more convenience oriented approach to sampling online activity in the past, I have more and more misgivings about this kind of ‘shot in the dark’ case selection that stands as one pole in the dichotomy of big and small data research on online activity. To take a more rigorous approach to sampling the data, I need to be able to represent it and cut it up in my own ways. This means I need to collect it in some sort of usable form.</p><p id="e8a9" class="jm jn cv v ab b jo jp jq jr js jt ju jv jw jx jy gk" data-selectable-paragraph="">I have worked with a number of different ways of scraping social media and web content, but for forums I find that the best tool is the <a href="http://webscraper.io/" class="bw dl kp kq kr ks" target="_blank" rel="noopener nofollow">http://webscraper.io</a> Chrome extension. Using webscraper I was able to build a tool that moved through all the threads and posts and collected the data to a <a href="http://couchdb.apache.org/" class="bw dl kp kq kr ks" target="_blank" rel="noopener nofollow">CouchDB</a> database that I could later export to a simple CSV file. Rather than store the raw html, I chose to scrape the text, hyperlinks, and images of each post as separate entities. This gave me plain text to work with and all the URLs referred to. I also collected the thread and post titles, poster, and timestamp. The resulting CSV file has a row for each post and the following columns:</p><p id="2169" class="jm jn cv v ab b jo jp jq jr js jt ju jv jw jx jy gk" data-selectable-paragraph=""><em class="kt">pagination_forum&gt;thread&gt;pagination_thread&gt;user&gt;time&gt;text&gt;links&gt;images</em></p><p id="c47e" class="jm jn cv v ab b jo jp jq jr js jt ju jv jw jx jy gk" data-selectable-paragraph="">I then took this CSV file and used <a href="http://www.barebones.com/products/textwrangler/" class="bw dl kp kq kr ks" target="_blank" rel="noopener nofollow">TextWrangler</a>’s brilliant ‘Zap Gremlins’ function to clean up some strange artefacts that appeared because of changes in text encoding.</p><h2 id="1e9c" class="jz ka cv v ba fh ib kb id kc kd ke kf kg kh ki kj">Re-threading the once threaded</h2><p id="d2c9" class="jm jn cv v ab b jo kk jq kl js km ju kn jw ko jy gk" data-selectable-paragraph="">One of the problems with scraping is that the order the scraper moves through a forum site may not follow the logical reading order for posts. This means that while I managed to collect all 650,000 posts into a series of spreadsheet files for each sub-forum, the order the posts appeared made threads totally unreadable. If I only wanted to perform descriptive statistical analysis on the posts this wouldn’t be a problem, but I want to analyse the discussions as interactions and so clearly they needed resorting.</p><p id="87be" class="jm jn cv v ab b jo jp jq jr js jt ju jv jw jx jy gk" data-selectable-paragraph="">I tried to import the CSV files into qualitative data analysis program <a href="http://www.maxqda.com/" class="bw dl kp kq kr ks" target="_blank" rel="noopener nofollow">MaxQDA</a> and use it to sort out the posts, but quickly realised that what I needed was to see each thread as separate document organised by sub-forum in the QDA database and not each post organised by thread. This meant that I needed to reconstitute the threads within the spreadsheet files and split each thread off as separate CSV files before importing them into MaxQDA. Fortunately, after a great deal of trying I managed to get Excel to perform the task:</p><ol><li id="36b8" class="jm jn cv v ab b jo jp jq jr js jt ju jv jw jx jy ku kv kw" data-selectable-paragraph="">I performed a custom sort on each spreadsheet. Level 1 of the sort was the thread title (this groups all the posts for a thread), and level 2 was the timestamp (this sorted the posts within each thread).</li><li id="398e" class="jm jn cv v ab b jo kx jq ky js kz ju la jw lb jy ku kv kw" data-selectable-paragraph="">I then used pivot tables to filter the data by thread and make each thread its own sheet.</li><li id="c01a" class="jm jn cv v ab b jo kx jq ky js kz ju la jw lb jy ku kv kw" data-selectable-paragraph="">Then I used <a href="http://www.accountingweb.co.uk/anyanswers/macro-exporting-50-worksheets-csv-one-pass" class="bw dl kp kq kr ks" target="_blank" rel="noopener nofollow">this VBA script</a> to automatically save each sheet as a new CSV file (VBA scripts only work easily on Windows versions of Excel so I was forced to fire-up the old virtual machine on my Mac to make this work).</li></ol><p id="9955" class="jm jn cv v ab b jo jp jq jr js jt ju jv jw jx jy gk" data-selectable-paragraph="">And voila! I imported the spreadsheets for each thread into MaxQDA and ended up with a threaded database of posts to search through and code.</p></div></article></main><footer class="footer"><div class="footer__copyright"><p>This site is based on the <a href="https://marketplace.getpublii.com/product/simple/">Simple</a> theme and built with the <a href="https://getpublii.com">Publii</a> static site CMS.</p></div><button class="footer__bttop js-footer__bttop" aria-label="Back to top | Tillbaka till toppen"><svg><title>Back to top | Tillbaka till toppen</title><use xlink:href="https://paddle-cluster.github.io/assets/svg/svg-map.svg#toparrow"/></svg></button></footer></div><script>window.publiiThemeMenuConfig = {    
        mobileMenuMode: 'sidebar',
        animationSpeed: 300,
        submenuWidth: 'auto',
        doubleClickTime: 500,
        mobileMenuExpandableSubmenus: true, 
        relatedContainerForOverlayMenuSelector: '.top',
   };</script><script defer="defer" src="https://paddle-cluster.github.io/assets/js/scripts.min.js?v=f56b13ba141d95ea2a0b7aab75ca9528"></script><script>var lazyFeaturedImage=function lazyFeaturedImage(){var b=document.querySelectorAll(".hero__image-img");for(var a=0;a<b.length;a++){var c=b[a];c.addEventListener("lazyloaded",function(f){var d=f.target.parentNode;d.classList.add("hero__image--overlay")})}};lazyFeaturedImage();</script></body></html>